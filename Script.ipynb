{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8G-x0E8OceZp"
   },
   "source": [
    "# TP de regresión (properati)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jw8ogMDOpvKP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import sklearn as sk\n",
    "from sklearn import model_selection\n",
    "from sklearn import ensemble\n",
    "from sklearn import metrics\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20D-m6GPyefp"
   },
   "source": [
    "# 1. Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=pd.read_csv(\"entrenamiento.csv\", index_col=\"id\")\n",
    "data_test = pd.read_csv(\"a_predecir.csv\", index_col=\"id\")\n",
    "df_train = data_train.copy()\n",
    "df_test = data_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zjaTnfxkyvo8"
   },
   "source": [
    "# 2. Limpieza y transformación de datos 🧹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tY5rbxzOoyYd"
   },
   "outputs": [],
   "source": [
    "#Renombro columnas\n",
    "df_train.rename(columns={'l1':'Pais','l2': 'Provincia','l3':'Barrio','l4':'Sub_barrio','lat':'lon','lon':'lat'}, inplace=True)\n",
    "df_test.rename(columns={'l1':'Pais','l2': 'Provincia','l3':'Barrio','l4':'Sub_barrio','lat':'lon','lon':'lat'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elimino duplicados, propiedades sin precio y propiedades con precio = 0\n",
    "df_train=df_train.drop_duplicates()\n",
    "df_train= df_train.dropna(subset=['price'])\n",
    "df_train = df_train[df_train['price']!= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titulo, descripcion y barrio a str y minusculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['title', 'description']] = df_train[['title', 'description']].astype(str)\n",
    "df_test[['title', 'description']] = df_test[['title', 'description']].astype(str)\n",
    "\n",
    "df_train['title'] = df_train['title'].str.lower()\n",
    "df_train['description'] = df_train['description'].str.lower()\n",
    "df_test['title'] = df_test['title'].str.lower()\n",
    "df_test['description'] = df_test['description'].str.lower()\n",
    "df_train['Barrio'] = df_train['Barrio'].str.lower()\n",
    "df_test['Barrio'] = df_test['Barrio'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separo en CASA DEPARTAMENTO COCHERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo filtros para separar tipo de propiedad\n",
    "filtro_casa=df_train.property_type== \"Casa\"\n",
    "filtro_depa=df_train.property_type==\"Departamento\"\n",
    "filtro_cochera=df_train.property_type==\"Cochera\"\n",
    "########\n",
    "filtro_casa_t=df_test.property_type==\"Casa\"\n",
    "filtro_depa_t=df_test.property_type==\"Departamento\"\n",
    "filtro_cochera_t=df_test.property_type==\"Cochera\"\n",
    "\n",
    "#parto df_train en 3. lo mismo para df_test\n",
    "df_train_casa=df_train.loc[filtro_casa]\n",
    "df_train_depa=df_train.loc[filtro_depa]\n",
    "df_train_cochera=df_train.loc[filtro_cochera]\n",
    "\n",
    "df_test_casa=df_test.loc[filtro_casa_t]\n",
    "df_test_depa=df_test.loc[filtro_depa_t]\n",
    "df_test_cochera=df_test.loc[filtro_cochera_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_eliminar=['property_type']\n",
    "\n",
    "df_train_casa.drop(col_eliminar, axis=1, inplace= True)\n",
    "df_train_depa.drop(col_eliminar, axis=1, inplace= True)\n",
    "df_train_cochera.drop(col_eliminar, axis=1, inplace= True)\n",
    "df_test_casa.drop(col_eliminar, axis=1, inplace= True)\n",
    "df_test_depa.drop(col_eliminar, axis=1, inplace= True)\n",
    "df_test_cochera.drop(col_eliminar, axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creo filtros para cada uno de los dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = df_test_casa['lat'].min()\n",
    "lat_max = df_test_casa['lat'].max()\n",
    "lon_min = df_test_casa['lon'].min()\n",
    "lon_max = df_test_casa['lon'].max()\n",
    "\n",
    "barrios_types_casa=df_test_casa['Barrio'].unique()\n",
    "\n",
    "df_train_casa = df_train_casa.loc[\n",
    "    (df_train_casa[\"Pais\"] == \"Argentina\") &\n",
    "    (df_train_casa[\"operation_type\"] == \"Venta\") &\n",
    "    (df_train_casa[\"currency\"] == 'USD') &\n",
    "    (df_train_casa[\"Barrio\"].isin(barrios_types_casa)) &\n",
    "    (df_train_casa[\"lat\"] >= lat_min) &\n",
    "    (df_train_casa[\"lat\"] <= lat_max) &\n",
    "    (df_train_casa[\"lon\"] >= lon_min) &\n",
    "    (df_train_casa[\"lon\"] <= lon_max)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPARTAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = df_test_depa['lat'].min()\n",
    "lat_max = df_test_depa['lat'].max()\n",
    "lon_min = df_test_depa['lon'].min()\n",
    "lon_max = df_test_depa['lon'].max()\n",
    "\n",
    "barrios_types_depa=df_test_depa['Barrio'].unique()\n",
    "\n",
    "df_train_depa = df_train_depa.loc[\n",
    "    (df_train_depa[\"Pais\"] == \"Argentina\") &\n",
    "    (df_train_depa[\"operation_type\"] == \"Venta\") &\n",
    "    (df_train_depa[\"currency\"] == 'USD') &\n",
    "    (df_train_depa[\"Barrio\"].isin(barrios_types_depa)) &\n",
    "    (df_train_depa[\"lat\"] >= lat_min) &\n",
    "    (df_train_depa[\"lat\"] <= lat_max) &\n",
    "    (df_train_depa[\"lon\"] >= lon_min) &\n",
    "    (df_train_depa[\"lon\"] <= lon_max)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para departamentos creo la columna monoambiente\n",
    "df_train_depa[\"monoambiente\"]=None\n",
    "df_test_depa[\"monoambiente\"]=None\n",
    "df_train_depa[\"monoambiente\"] = df_train_depa['description'].str.contains(\"monoambiente\", case=False, na=False)\n",
    "df_test_depa[\"monoambiente\"] = df_test_depa['description'].str.contains(\"monoambiente\", case=False, na=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCHERA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min = df_test_depa['lat'].min()\n",
    "lat_max = df_test_depa['lat'].max()\n",
    "lon_min = df_test_depa['lon'].min()\n",
    "lon_max = df_test_depa['lon'].max()\n",
    "\n",
    "barrios_types_cochera=df_test_cochera['Barrio'].unique()\n",
    "\n",
    "df_train_cochera = df_train_cochera.loc[\n",
    "    (df_train_cochera[\"Pais\"] == \"Argentina\") &\n",
    "    (df_train_cochera[\"operation_type\"] == \"Venta\") &\n",
    "    (df_train_cochera[\"currency\"] == 'USD') &\n",
    "    (df_train_cochera[\"Barrio\"].isin(barrios_types_cochera)) &\n",
    "    (df_train_cochera[\"lat\"] >= lat_min) &\n",
    "    (df_train_cochera[\"lat\"] <= lat_max) &\n",
    "    (df_train_cochera[\"lon\"] >= lon_min) &\n",
    "    (df_train_cochera[\"lon\"] <= lon_max)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### elimino de train/test cochera los ambientes\n",
    "col_eliminar=['rooms','bedrooms','bathrooms']\n",
    "df_train_cochera.drop(col_eliminar, axis=1, inplace= True)\n",
    "df_test_cochera.drop(col_eliminar, axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuevas columnas a partir de description y title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_caracteristicas(df, col1=\"title\", col2=\"description\"):\n",
    "    features = [\"gym\", \"sum\", \"parrilla\", \"loundry\", \"soleado\", \"subte\", \"terraza\", \"pileta\", \"jacuzzi\", \"balcon\"]\n",
    "    for feature in features:\n",
    "        df[f\"{feature}_r\"] = 0\n",
    "\n",
    "    patrones = {\n",
    "        \"gym\": r\"(gym|gimnasio)\",\n",
    "        \"sum\": r\"\\bsum\\b\",\n",
    "        \"parrilla\": r\"\\bparrilla\\b\",\n",
    "        \"loundry\": r\"\\bloundry\\b\",\n",
    "        \"soleado\": r\"\\bsoleado\\b\",\n",
    "        \"subte\": r\"\\bsubte\\b\",\n",
    "        \"terraza\": r\"\\bterraza\\b\",\n",
    "        \"pileta\": r\"\\bpileta\\b\",\n",
    "        \"jacuzzi\": r\"([JjYy]acu[zs]{1,2}i)\",\n",
    "        \"balcon\": r\"\\bbalc[oó]n\\b\"\n",
    "    }\n",
    "\n",
    "    for feature, pattern in patrones.items():\n",
    "        df[f\"{feature}_r\"] += df[col1].str.contains(pattern, case=False, na=False).astype(int)\n",
    "        df[f\"{feature}_r\"] += df[col2].str.contains(pattern, case=False, na=False).astype(int)\n",
    "\n",
    "    for feature in features:\n",
    "        df[f\"{feature}_r\"] = df[f\"{feature}_r\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    df['lujoso'] = df[[f\"{feature}_r\" for feature in features]].sum(axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregar_caracteristicas(df_train_depa)\n",
    "agregar_caracteristicas(df_train_casa)\n",
    "agregar_caracteristicas(df_test_casa)\n",
    "agregar_caracteristicas(df_test_depa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agregar_caracteristicas_cochera(df, col1=\"title\", col2=\"description\"):\n",
    "    features = [\"garage en block\", \"galpón cocheras\", \"cochera deposito\", \n",
    "                \"cocheras + local+ deposito en san cristóbal\", \"paquete de cocheras\",\"cocheras cubiertas\",\"edificio de cocheras\"]\n",
    "    for feature in features:\n",
    "        df[f\"{feature}_r\"] = 0\n",
    "\n",
    "    patrones = {\n",
    "        \"garage en block\": r\"\\bgarage en block\\b\",\n",
    "        \"galpón cocheras\": r\"\\bgalpón cocheras\\b\",\n",
    "        \"cochera deposito\": r\"\\bcochera deposito\\b\",\n",
    "        \"cocheras cubiertas\": r\"\\bcocheras cubiertas\\b\",\n",
    "        \"edificio de cocheras\":r\"\\bedificio de cocheras\\b\",\n",
    "        \"cocheras + local+ deposito en san cristóbal\": r\"\\bcocheras \\+ local\\+ deposito en san cristóbal\\b\",\n",
    "        \"paquete de cocheras\": r\"\\bpaquete de cocheras\\b\"\n",
    "    }\n",
    "\n",
    "    for feature, pattern in patrones.items():\n",
    "        df[f\"{feature}_r\"] = (df[col1].str.contains(pattern, case=False, na=False).astype(int) |\n",
    "                              df[col2].str.contains(pattern, case=False, na=False).astype(int))\n",
    "\n",
    "    df[\"COMPLEJO COCHERAS\"] = df[[f\"{feature}_r\" for feature in features]].any(axis=1).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agregar_caracteristicas_cochera(df_train_cochera)\n",
    "agregar_caracteristicas_cochera(df_test_cochera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrar el barrio de propiedad en el titulo o descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_barrios(df, columna1, columna2, lista_barrios):\n",
    "    lista_barrios=lista_barrios.astype(\"str\")\n",
    "    barrios= [palabra.lower() for palabra in lista_barrios]\n",
    "    def buscar_barrio(texto):\n",
    "        for barrio in barrios:\n",
    "            if barrio in texto:\n",
    "                return barrio\n",
    "        return \"Nada\"\n",
    "    \n",
    "    df['barrios_encontrados_title'] = df[columna1].apply(buscar_barrio)\n",
    "    df['barrios_encontrados_description'] = df[columna2].apply(buscar_barrio)\n",
    "    return df\n",
    "\n",
    "def encontrar_consenso(row):\n",
    "    titulo = row['barrios_encontrados_title']\n",
    "    descripcion = row['barrios_encontrados_description']\n",
    "    if titulo == \"Nada\" and descripcion== \"Nada\":\n",
    "        return None\n",
    "    elif descripcion == \"Nada\" and titulo !=\"Nada\":\n",
    "        return titulo\n",
    "    elif titulo == \"Nada\" and descripcion !=\"Nada\":\n",
    "        return descripcion\n",
    "    else:\n",
    "        return titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_casa=encontrar_barrios(df_train_casa,\"title\",\"description\",barrios_types_casa)\n",
    "df_test_casa=encontrar_barrios(df_test_casa,\"title\",\"description\",barrios_types_casa)\n",
    "df_train_casa['consenso_barrios'] = df_train_casa.apply(encontrar_consenso, axis=1)\n",
    "df_test_casa['consenso_barrios'] = df_test_casa.apply(encontrar_consenso, axis=1)\n",
    "\n",
    "df_train_depa=encontrar_barrios(df_train_depa,\"title\",\"description\",barrios_types_depa)\n",
    "df_test_depa=encontrar_barrios(df_test_depa,\"title\",\"description\",barrios_types_depa)\n",
    "df_train_depa['consenso_barrios'] = df_train_depa.apply(encontrar_consenso, axis=1)\n",
    "df_test_depa['consenso_barrios'] = df_test_depa.apply(encontrar_consenso, axis=1)\n",
    "\n",
    "df_train_cochera=encontrar_barrios(df_train_cochera,\"title\",\"description\",barrios_types_cochera)\n",
    "df_test_cochera=encontrar_barrios(df_test_cochera,\"title\",\"description\",barrios_types_cochera)\n",
    "df_train_cochera['consenso_barrios'] = df_train_cochera.apply(encontrar_consenso, axis=1)\n",
    "df_test_cochera['consenso_barrios'] = df_test_cochera.apply(encontrar_consenso, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completo los valores faltantes de los barrios segun el consenso que arme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_casa.loc[df_train_casa['Barrio'].isna(), 'Barrio'] = df_train_casa['consenso_barrios']\n",
    "df_train_depa.loc[df_train_depa['Barrio'].isna(), 'Barrio'] = df_train_depa['consenso_barrios']\n",
    "df_test_casa.loc[df_test_casa['Barrio'].isna(), 'Barrio'] = df_test_casa['consenso_barrios']\n",
    "df_test_depa.loc[df_test_depa['Barrio'].isna(), 'Barrio'] = df_test_depa['consenso_barrios']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divido palermo con los sub_barrios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_casa.loc[df_train_casa['Barrio'] == 'Palermo', 'Barrio'] = df_train_casa['Sub_barrio']\n",
    "df_test_casa.loc[df_test_casa['Barrio'] == 'Palermo', 'Barrio'] = df_test_casa['Sub_barrio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_depa.loc[df_train_depa['Barrio'] == 'Palermo', 'Barrio'] = df_train_depa['Sub_barrio']\n",
    "df_test_depa.loc[df_test_depa['Barrio'] == 'Palermo', 'Barrio'] = df_test_depa['Sub_barrio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUPERFICIE TOTAL VS CUBIERTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invertir_superficies(df):\n",
    "    # filtro las filas que tienen mayor superficie cubierta que total\n",
    "    f = df['surface_covered'] > df['surface_total']\n",
    "    df.loc[f, ['surface_total', 'surface_covered']] = df.loc[f, ['surface_covered', 'surface_total']].values\n",
    "    return df\n",
    "\n",
    "def asignar_superficie_total(df):\n",
    "    # Primero, intenta completar 'surface_total' con 'surface_covered' si 'surface_total' es NaN\n",
    "    df['surface_total'] = df['surface_total'].where(pd.notnull(df['surface_total']), df['surface_covered'])\n",
    "    \n",
    "    # Luego, intenta completar 'surface_covered' con 'surface_total' si 'surface_covered' es NaN\n",
    "    df['surface_covered'] = df['surface_covered'].where(pd.notnull(df['surface_covered']), df['surface_total'])\n",
    "    return df\n",
    "\n",
    "\n",
    "df_train_casa=invertir_superficies(df_train_casa)\n",
    "df_train_depa=invertir_superficies(df_train_depa)\n",
    "df_train_cochera=invertir_superficies(df_train_cochera)\n",
    "\n",
    "df_test_casa=invertir_superficies(df_test_casa)\n",
    "df_test_depa=invertir_superficies(df_test_depa)\n",
    "df_test_cochera=invertir_superficies(df_test_cochera)\n",
    "\n",
    "df_train_casa=asignar_superficie_total(df_train_casa)\n",
    "df_train_depa=asignar_superficie_total(df_train_depa)\n",
    "df_train_cochera=asignar_superficie_total(df_train_cochera)\n",
    "\n",
    "df_test_casa=asignar_superficie_total(df_test_casa)\n",
    "df_test_depa=asignar_superficie_total(df_test_depa)\n",
    "df_test_cochera=asignar_superficie_total(df_test_cochera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputacion de outliers para superficie total y cubierta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_depa.loc[139033, ['surface_total','surface_covered']] = 47.63\n",
    "df_train_depa.loc[275571, 'surface_total'] = 108.96\n",
    "df_train_depa.loc[581682, ['surface_total','surface_covered']] = 104.89\n",
    "df_train_depa.loc[742758, 'surface_total'] = 48.17\n",
    "df_train_depa.loc[942718, ['surface_total','surface_covered']] = 104.89\n",
    "df_train_depa.loc[994027, ['surface_total','surface_covered']] = 21.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_depa.loc[973771, 'surface_total'] = 69\n",
    "df_test_depa.loc[973771, 'surface_covered'] = 63\n",
    "df_test_depa.loc[899423, 'surface_total'] = 81\n",
    "df_test_depa.loc[899423, 'surface_covered'] = 71.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_casa.loc[49928, 'surface_total'] = 377.38\n",
    "df_train_casa.loc[49928, 'surface_covered'] = 219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_cochera.loc[865148, 'surface_total'] = 20.5\n",
    "df_train_cochera.drop(865149,inplace=True)### misma propiedad que la anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_cochera.loc[866125, 'surface_total'] = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Si conozco el barrio puedo imputar la lat y lon con el promedio de cada variable por barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_barrio_depa=df_train_depa.groupby(\"Barrio\").lat.mean().reset_index().set_index(\"Barrio\")\n",
    "lon_barrio_depa=df_train_depa.groupby(\"Barrio\").lon.mean().reset_index().set_index(\"Barrio\")\n",
    "\n",
    "lat_barrio_casa=df_train_casa.groupby(\"Barrio\").lat.mean().reset_index().set_index(\"Barrio\")\n",
    "lon_barrio_casa=df_train_casa.groupby(\"Barrio\").lon.mean().reset_index().set_index(\"Barrio\")\n",
    "\n",
    "lat_barrio_cochera=df_train_cochera.groupby(\"Barrio\").lat.mean().reset_index().set_index(\"Barrio\")\n",
    "lon_barrio_cochera=df_train_cochera.groupby(\"Barrio\").lon.mean().reset_index().set_index(\"Barrio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_lat_depa = df_train_depa['lat'].isna()\n",
    "missing_lon_depa = df_train_depa['lon'].isna()\n",
    "\n",
    "missing_lat_casa = df_train_casa['lat'].isna()\n",
    "missing_lon_casa = df_train_casa['lon'].isna()\n",
    "\n",
    "missing_lat_cochera = df_train_cochera['lat'].isna()\n",
    "missing_lon_cochera = df_train_cochera['lon'].isna()\n",
    "\n",
    "# Completo los faltantes en train\n",
    "df_train_depa.loc[missing_lat_depa, 'lat'] = df_train_depa.loc[missing_lat_depa, 'Barrio'].map(lat_barrio_depa['lat'])\n",
    "df_train_depa.loc[missing_lon_depa, 'lon'] = df_train_depa.loc[missing_lon_depa, 'Barrio'].map(lon_barrio_depa['lon'])\n",
    "\n",
    "df_train_casa.loc[missing_lat_casa, 'lat'] = df_train_casa.loc[missing_lat_casa, 'Barrio'].map(lat_barrio_casa['lat'])\n",
    "df_train_casa.loc[missing_lon_casa, 'lon'] = df_train_casa.loc[missing_lon_casa, 'Barrio'].map(lon_barrio_casa['lon'])\n",
    "\n",
    "df_train_cochera.loc[missing_lat_cochera, 'lat'] = df_train_cochera.loc[missing_lat_cochera, 'Barrio'].map(lat_barrio_cochera['lat'])\n",
    "df_train_cochera.loc[missing_lon_cochera, 'lon'] = df_train_cochera.loc[missing_lon_cochera, 'Barrio'].map(lon_barrio_cochera['lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_lat_depa = df_test_depa['lat'].isna()\n",
    "missing_lon_depa = df_test_depa['lon'].isna()\n",
    "\n",
    "missing_lat_casa = df_test_casa['lat'].isna()\n",
    "missing_lon_casa = df_test_casa['lon'].isna()\n",
    "\n",
    "missing_lat_cochera = df_test_cochera['lat'].isna()\n",
    "missing_lon_cochera = df_test_cochera['lon'].isna()\n",
    "\n",
    "\n",
    "# Completo los faltantes en test\n",
    "df_test_depa.loc[missing_lat_depa, 'lat'] = df_test_depa.loc[missing_lat_depa, 'Barrio'].map(lat_barrio_depa['lat'])\n",
    "df_test_depa.loc[missing_lon_depa, 'lon'] = df_test_depa.loc[missing_lon_depa, 'Barrio'].map(lon_barrio_depa['lon'])\n",
    "\n",
    "df_test_casa.loc[missing_lat_casa, 'lat'] = df_test_casa.loc[missing_lat_casa, 'Barrio'].map(lat_barrio_casa['lat'])\n",
    "df_test_casa.loc[missing_lon_casa, 'lon'] = df_test_casa.loc[missing_lon_casa, 'Barrio'].map(lon_barrio_casa['lon'])\n",
    "\n",
    "df_test_cochera.loc[missing_lat_cochera, 'lat'] = df_test_cochera.loc[missing_lat_cochera, 'Barrio'].map(lat_barrio_cochera['lat'])\n",
    "df_test_cochera.loc[missing_lon_cochera, 'lon'] = df_test_cochera.loc[missing_lon_cochera, 'Barrio'].map(lon_barrio_cochera['lon'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promedio de precio por barrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "price_barrio_depa = df_train_depa.groupby(\"Barrio\").price.median().round().astype(int).reset_index().set_index(\"Barrio\")\n",
    "price_barrio_casa=df_train_casa.groupby(\"Barrio\").price.median().round().astype(int).reset_index().set_index(\"Barrio\")\n",
    "price_barrio_cochera=df_train_cochera.groupby(\"Barrio\").price.median().round().astype(int).reset_index().set_index(\"Barrio\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "price_barrio_depa = df_train_depa.groupby(\"Barrio\").price.mean().round().astype(int).reset_index().set_index(\"Barrio\")\n",
    "price_barrio_casa=df_train_casa.groupby(\"Barrio\").price.mean().round().astype(int).reset_index().set_index(\"Barrio\")\n",
    "price_barrio_cochera=df_train_cochera.groupby(\"Barrio\").price.mean().round().astype(int).reset_index().set_index(\"Barrio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_depa[\"promedio_barrio\"] = df_train_depa[\"Barrio\"].map(price_barrio_depa[\"price\"])\n",
    "df_train_casa[\"promedio_barrio\"] = df_train_casa[\"Barrio\"].map(price_barrio_depa[\"price\"])\n",
    "df_train_cochera[\"promedio_barrio\"] = df_train_cochera[\"Barrio\"].map(price_barrio_depa[\"price\"])\n",
    "\n",
    "df_test_depa[\"promedio_barrio\"] = df_test_depa[\"Barrio\"].map(price_barrio_depa[\"price\"])\n",
    "df_test_casa[\"promedio_barrio\"] = df_test_casa[\"Barrio\"].map(price_barrio_depa[\"price\"])\n",
    "df_test_cochera[\"promedio_barrio\"] = df_test_cochera[\"Barrio\"].map(price_barrio_depa[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=100, random_state=42)  \n",
    "imputed_values=imp.fit_transform(df_train_casa[['lon', 'lat', 'rooms', 'bedrooms',\"bathrooms\",\"surface_total\",\"surface_covered\",\"promedio_barrio\"]])\n",
    "\n",
    "df_train_casa[['lon', 'lat', 'rooms', 'bedrooms', 'bathrooms', 'surface_total', 'surface_covered',\"promedio_barrio\"]] = imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=100, random_state=42) \n",
    "imputed_values=imp.fit_transform(df_train_depa[['lon', 'lat', 'rooms', 'bedrooms',\"bathrooms\",\"surface_total\",\"surface_covered\",\"promedio_barrio\"]])\n",
    "\n",
    "df_train_depa[['lon', 'lat', 'rooms', 'bedrooms', 'bathrooms', 'surface_total', 'surface_covered',\"promedio_barrio\"]] = imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=100, random_state=42)  # tiene add_indicator\n",
    "imputed_values=imp.fit_transform(df_train_cochera[['lon', 'lat',\"surface_total\",\"surface_covered\",\"promedio_barrio\"]])\n",
    "\n",
    "df_train_cochera[['lon', 'lat', 'surface_total', 'surface_covered',\"promedio_barrio\"]] = imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=100, random_state=42)  # tiene add_indicator\n",
    "imputed_values=imp.fit_transform(df_test_casa[['lon', 'lat', 'rooms', 'bedrooms',\"bathrooms\",\"promedio_barrio\"]])\n",
    "\n",
    "df_test_casa[['lon', 'lat', 'rooms', 'bedrooms', 'bathrooms',\"promedio_barrio\"]] = imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = IterativeImputer(max_iter=100, random_state=42)  # tiene add_indicator\n",
    "imputed_values=imp.fit_transform(df_test_depa[['lon', 'lat', 'rooms', 'bedrooms',\"bathrooms\",\"promedio_barrio\"]])\n",
    "\n",
    "df_test_depa[['lon', 'lat', 'rooms', 'bedrooms', 'bathrooms',\"promedio_barrio\"]] = imputed_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columnas a eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhXr9Qis6ZZE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Columnas a eliminar desp de una chusmeada, en ambos df, de momento creo q no me aportan\n",
    "col_eliminar_casa=[\"consenso_barrios\",\"barrios_encontrados_description\",\"barrios_encontrados_title\",\"Barrio\",'Pais','Provincia','operation_type','Sub_barrio','l5','l6','price_period','title','description','ad_type','start_date','end_date','created_on','currency']\n",
    "col_eliminar_depa=[\"consenso_barrios\",\"barrios_encontrados_description\",\"barrios_encontrados_title\",\"Barrio\",'Pais','Provincia','operation_type','Sub_barrio','l5','l6','price_period','title','description','ad_type','start_date','end_date','created_on','currency']\n",
    "col_eliminar_cochera=['garage en block_r', 'galpón cocheras_r',\n",
    "       'cochera deposito_r', 'cocheras + local+ deposito en san cristóbal_r',\n",
    "       'paquete de cocheras_r', 'cocheras cubiertas_r',\n",
    "       'edificio de cocheras_r',\"consenso_barrios\",\"barrios_encontrados_description\",\"barrios_encontrados_title\",\"Barrio\",'Pais','Provincia','operation_type','Sub_barrio','l5','l6','price_period','title','description','ad_type','start_date','end_date','created_on','currency']\n",
    "\n",
    "df_train_casa.drop(col_eliminar_casa, axis=1, inplace= True)\n",
    "df_train_depa.drop(col_eliminar_depa, axis=1, inplace= True)\n",
    "df_train_cochera.drop(col_eliminar_cochera, axis=1, inplace= True)\n",
    "\n",
    "df_test_casa.drop(col_eliminar_casa, axis=1, inplace= True)\n",
    "df_test_depa.drop(col_eliminar_depa, axis=1, inplace= True)\n",
    "df_test_cochera.drop(col_eliminar_cochera, axis=1, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplico el log10 a precio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_log_base_10_a_columna(df, columna=\"price\"):\n",
    "    df[columna] = np.log10(df[columna])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aplicar_log_base_10_a_columna(df_train_depa)\n",
    "aplicar_log_base_10_a_columna(df_train_casa)\n",
    "aplicar_log_base_10_a_columna(df_train_cochera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2jRJmQ-tD4Z"
   },
   "source": [
    "# 3. Entrenamiento del Modelo con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wpS9E1RbRtYm"
   },
   "outputs": [],
   "source": [
    "def entrenamiento(df):\n",
    "    df = df.select_dtypes(include=['float64', 'int64', 'int32', 'int16', 'int8', 'bool'])\n",
    "\n",
    "    X = df[df.columns.drop('price')]\n",
    "    y = df['price']\n",
    "    \n",
    "    for n_estimators in [50,75,100,1000]:\n",
    "        for max_depth in [5,10,20,30,40]:\n",
    "            print(f\"{n_estimators=} -- {max_depth=}\")\n",
    "\n",
    "            # Creamos el modelo\n",
    "            reg = sk.ensemble.RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth,n_jobs=-1, random_state=42)\n",
    "\n",
    "            scores_train = []\n",
    "            scores_test = []\n",
    "\n",
    "            # Validación cruzada, 10 folds, shuffle antes, semilla aleatoria\n",
    "            kf = sk.model_selection.KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "            for fold, (train_index, test_index) in enumerate(kf.split(X, y)):\n",
    "                # Partimos el fold en entrenamiento y prueba...\n",
    "                X_train, X_test, y_train, y_test = X.iloc[train_index], X.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "                # Entrenamos el modelo en entramiento\n",
    "                reg.fit(X_train, y_train)\n",
    "\n",
    "                # Predecimos en train\n",
    "                y_pred = reg.predict(X_train)\n",
    "\n",
    "                # Medimos la performance de la predicción en entramiento\n",
    "                score_train = sk.metrics.mean_squared_error(y_train, y_pred, squared=False)\n",
    "                scores_train.append(score_train)\n",
    "\n",
    "                # Predecimos en test\n",
    "                y_pred = reg.predict(X_test)\n",
    "\n",
    "                # Medimos la performance de la predicción en prueba\n",
    "                score_test = sk.metrics.mean_squared_error(y_test, y_pred, squared=False)\n",
    "                scores_test.append(score_test)\n",
    "\n",
    "                print(\"\\t\", f\"{fold=}, {score_train=} {score_test=}\")\n",
    "\n",
    "            print(f\"Media de scores en entrenamiento={pd.Series(scores_train).mean()}, std={pd.Series(scores_train).std()}\")\n",
    "            print(f\"Media de scores en prueba={pd.Series(scores_test).mean()}, std={pd.Series(scores_test).std()}\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento(df_train_casa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento(df_train_depa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento(df_train_cochera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqVkTPzj3kV0"
   },
   "source": [
    "# 4. Predicción para kaggle -- ⚠️⚠️⚠️ MODIFICAR HIPERPARÁMETROS ⚠️⚠️⚠️\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01697gx81F5Z"
   },
   "outputs": [],
   "source": [
    "def predecir(df_train,df_test,n_estimators,max_depth):\n",
    "    ## Datos a predecir\n",
    "    X = df_train[df_train.columns.drop('price')]\n",
    "    y = df_train['price']\n",
    "\n",
    "    X_test = df_test[df_train.columns.drop('price')]\n",
    "\n",
    "    reg = sk.ensemble.RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, n_jobs=-1, random_state=42)\n",
    "    reg.fit(X, y)\n",
    "\n",
    "    # Predecimos\n",
    "    df_test['price'] = reg.predict(X_test)\n",
    "\n",
    "    # Creamos el dataframe para entregar\n",
    "    df_sol = df_test[[\"price\"]]\n",
    "    return df_sol,reg,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predic_casa,mod_casa,X=predecir(df_train_casa,df_test_casa,1000,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predic_depa,mod_depa,X=predecir(df_train_depa,df_test_depa,1000,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_cochera,mod_cochera,X=predecir(df_train_cochera,df_test_cochera,1000,40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concateno las 3 predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol = pd.concat([predic_casa, predic_depa, predic_cochera], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora revierto el log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revertir_log_base_10_a_columna(df, columna=\"price\"):\n",
    "    df[columna] = np.power(10, df[columna])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revertir_log_base_10_a_columna(df_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redondeo el precio\n",
    "df_sol['price'] = df_sol['price'].round()\n",
    "df_sol['price'] = df_sol['price'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3sYxKVtDgqsS"
   },
   "outputs": [],
   "source": [
    "# Tests de validación de la predicción antes de subirla\n",
    "# Estos tests TIENEN que pasar sin error\n",
    "\n",
    "assert (df_sol[\"price\"] <= 0).sum() == 0, \"Hay predicciones de precios menores o iguales a 0.\"\n",
    "assert df_sol.shape[0] == 7808, f\"La cantidad de filas no es correcta. Es {df_sol.shape[0]} y debe ser 7808.\"\n",
    "assert df_sol.shape[1] == 1, f\"La cantidad de columnas no es correcta. Es {df_sol.shape[1]} y debe ser 1.\"\n",
    "assert 'price' in df_sol.columns, \"Falta la columna 'price'.\"\n",
    "assert df_sol.index.name == 'id', \"El índice debe llamarse 'id'.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputacion del precio de una cochera a predecir que tenia el precio en la descripcion\n",
    "df_sol.loc[274482, 'price'] = 2500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0iPfxeQYgrB6"
   },
   "outputs": [],
   "source": [
    "# Guardamos la version\n",
    "version = \"v-FINAL - Fpicado\"\n",
    "df_sol['price'].to_csv(f\"solucion-{version}.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = mod_cochera.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in mod_cochera.estimators_], axis=0)\n",
    "\n",
    "forest_importances = pd.Series(importances, index=X.columns.to_list())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "byV0dQi-yiEd"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
